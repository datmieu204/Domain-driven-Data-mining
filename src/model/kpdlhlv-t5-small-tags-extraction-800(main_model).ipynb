{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets evaluate rouge_score\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!huggingface-cli login --token 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\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wandb\n\n# Login using your API token\nwandb.login(key=\"2d37e955867ab5eab6ac3df9cf4827a5d28f1fc5\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data loading","metadata":{}},{"cell_type":"code","source":"from datasets import DatasetDict,load_dataset,concatenate_datasets\n\n\n# Load the dataset\ndata = load_dataset(\"lengocquangLAB/vie-news-tags-extraction\")\n\n# Lấy 100 dòng đầu tiên từ các split 'train' và 'test' sử dụng select()\n# train_subset = data['train'].select(range(100))\n# test_subset = data['test'].select(range(100))\n\ntrain_subset = data['train']\ntrain_fake_subset = data['test']\n\ntrain_subset = concatenate_datasets([train_subset, train_fake_subset])\n\n\n# test_subset = data['validation'].select(range(500))\ntest_subset = data['validation']\n\n\n# Merge the subsets back into a DatasetDict\ndata = DatasetDict({\n    'train': train_subset,\n    'test': test_subset\n})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"import ast\nfrom datasets import DatasetDict, load_dataset\n\n# Define a function to process each tags string\ndef process_tags(example):\n    # Convert the string representation of the list into an actual list\n    tags_list = ast.literal_eval(example['tags'])\n    # Join the list elements into a single string separated by commas\n    formatted_tags = ', '.join(tags_list)\n    # Return the updated example with the transformed tags\n    return {'tags': formatted_tags}\n\n# Apply the transformation to the 'tags' column in both train and test datasets\ndata['train'] = data['train'].map(process_tags)\ndata['test'] = data['test'].map(process_tags)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['train']['tags'][0]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"lengocquangLAB/t5-small-tags-extraction-800\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_function(examples):\n    model_inputs = tokenizer(examples[\"content\"], max_length=800, truncation=True)\n\n    labels = tokenizer(text_target=examples[\"tags\"], max_length=1024, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_data = data.map(preprocess_function, batched=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nrouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n\n    # Clip predictions to the valid range\n    predictions = np.clip(predictions, 0, tokenizer.vocab_size - 1)\n\n    # Decode predictions and labels\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Compute metrics\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n\n    # Add length statistics\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    print(\"Predictions:\", decoded_preds[-1])  # Inspect a few predictions\n    print(\"Labels:\", decoded_labels[-1])     # Inspect the corresponding references\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\n# Load the model using TensorFlow weights or PyTorch weights if available.\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n\n# Define training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"t5-small-tags-extraction-800\",\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    save_total_limit=1,\n    num_train_epochs=1,\n    predict_with_generate=True,\n    generation_max_length=100,\n    fp16=True,\n    push_to_hub=True,\n    logging_dir=\"./logs\",\n    logging_steps=10,  # Log every 10 steps (adjust as needed)\n    report_to=[\"tensorboard\"],\n)\n\n# Initialize the trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n# Train and push to hub multiple times if needed\nfor i in range(2):\n    trainer.train()\n    trainer.push_to_hub(commit_message=f\"Training iteration {i+1}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}